{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load all data\n",
    "frames = []\n",
    "for filename in os.listdir(\"./data/newssources\"):\n",
    "    frame = pd.read_json(\"./data/newssources/\"+filename, lines=True)\n",
    "    frames.append(frame)\n",
    "df_raw = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store df_raw\n",
    "%store -r df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_raw[\"id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data size\n",
    "print(len(df_raw))\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered for specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered for specific columns\n",
    "col_names = ['id', 'date', 'updated', 'title', 'caption', 'expandedLinks', 'link', 'postUrl', 'subscriberCount', 'score', 'statistics', 'account']\n",
    "df_cols = df_raw[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cols[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Account Column Values as Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Expanding statistics and account columns\n",
    "df_acc = df_cols.join(pd.json_normalize(df_cols['account']).add_prefix('account_'))\n",
    "df_acc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_raw[\"id\"].unique()))\n",
    "print(len(df_acc[\"id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = df_acc.drop(columns=['account', 'account_profileImage', 'account_platform', 'account_platformId'])\n",
    "df_acc[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Statistics Column Values as Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_col = df_acc.statistics.apply(lambda x: x['actual'])\n",
    "df_stat = df_acc.join(pd.json_normalize(stat_col).add_prefix('statistics_'))\n",
    "df_stat[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat = df_stat.drop(columns=['statistics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding rows based on 'expandedLinks' column values. One row each for every 'original' (unique) key in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat['expandedLinks'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rows with no expandedLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_raw[df_raw['expandedLinks'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[df_raw['expandedLinks'].isnull()][['expandedLinks', 'link', 'postUrl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = df_stat.explode('expandedLinks').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_exp))\n",
    "print(len(df_exp.groupby('id').count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_count = df_exp[['expandedLinks', 'id']].groupby('id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_count.sort_values('expandedLinks', ascending=False)[2600:2605]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[df_raw['id'] == 111599342312]['expandedLinks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_link_original = df_exp.expandedLinks.apply(lambda x: x['expanded'] if not pd.isnull(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_link_original[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = df_exp.rename(columns={'expandedLinks': 'expandedLinksRaw'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final = df_stat.join(df_exp).drop(columns='expandedLinks')\n",
    "df_final = df_exp.join(expanded_link_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[df_final['id'] == 111599342312][['id', 'expandedLinksRaw', 'expandedLinks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying that 'original' url has been extracted from allnon-null expandedLinks \n",
    "\n",
    "lost = df_final[df_final['expandedLinks'].isnull() & df_final['expandedLinksRaw'].notnull()][['expandedLinks', 'expandedLinksRaw']]\n",
    "lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = ['id', 'date', 'updated', 'title', 'caption', 'expandedLinks', 'link', 'postUrl',\n",
    "       'subscriberCount', 'score', 'account_id', 'account_name',\n",
    "       'account_handle', 'account_subscriberCount', 'account_url',\n",
    "       'account_accountType', 'account_pageAdminTopCountry',\n",
    "       'account_verified', 'statistics_likeCount', 'statistics_shareCount',\n",
    "       'statistics_commentCount', 'statistics_loveCount',\n",
    "       'statistics_wowCount', 'statistics_hahaCount', 'statistics_sadCount',\n",
    "       'statistics_angryCount', 'statistics_thankfulCount',\n",
    "       'statistics_careCount']\n",
    "news_df = df_final[final_cols].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No. of Unique Ids/Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_posts_by_id = len(news_df[\"id\"].unique())\n",
    "unique_posts_by_links = len(news_df[\"link\"].unique())\n",
    "print(\"Unique Post Ids: \", unique_posts_by_id)\n",
    "print(\"Unique Post Links: \", unique_posts_by_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[news_df['id'] == 111599342312]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving news_df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_df.to_csv('news_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading NewsGuardTech Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/ratings/newsguard-ratings.json\") as f:\n",
    "    ratings = f.read()\n",
    "ratings_data = json.loads(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.DataFrame(ratings_data.items(), columns=['domain', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = r'(?i)(.*h?t?tps?://)?(\\w*(-->>|:))?(www\\.)?([A-Za-z_0-9.-]+).*'\n",
    "exp = r'(?i)(.*h?t?tps?://)?(www\\.)?([A-Za-z_0-9.-]+).*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['domain'] = news_df.expandedLinks.str.extract(exp, expand=True)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[['expandedLinks', 'domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC\n",
    "len(news_df[news_df['expandedLinks'].notnull() & news_df['domain'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection of newsguardtech api domains and crowdtangle api domains\n",
    "ratings_domains_set = set(ratings_df['domain'].unique())\n",
    "ct_domains_set = set(news_df['domain'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ct_domains_set.difference(ratings_domains_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo:\n",
    "pre-tasks: correct domain column \n",
    "1. include ratings column\n",
    "2. include credible (t/f) column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandasql as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_expanded_links = ps.sqldf(\"select id, expandedLinks, domain from news_df where domain not like '%.%'\")\n",
    "# news_df[~news_df[\"domain\"].str.contains('.', na=False)][['id', 'expandedLinks', 'domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_expanded_links.to_csv('invalid_expanded_links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(invalid_expanded_links.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad data\n",
    "df_raw[df_raw['id'] == 111663444165]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_exp_data = df_raw[df_raw['id'].isin(invalid_expanded_links.id.to_list())][['id', 'expandedLinks']]\n",
    "invalid_exp_data.to_csv('invalid_exp_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[(news_df['id'].isin(invalid_expanded_links.id.to_list())) & (news_df['domain'].str.contains('.'))][['id', 'expandedLinks', 'domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[news_df['id'] == 111677826151]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expanding short urls to obtain the correct domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## wherever rating = NaN, get expandedLink - parse it for domain using requests\n",
    "to_get_expanded_url = news_df[news_df.domain.isin(['trib.al', 'bit.ly', 'tinyurl.com'])][['id', 'expandedLinks', 'domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(to_get_expanded_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_url_list = to_get_expanded_url.expandedLinks.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(short_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_domain(url):\n",
    "    exp = r'(?i)(.*h?t?tps?://)?(www\\.)?([A-Za-z_0-9.-]+).*'\n",
    "    try:\n",
    "        search = re.search(exp, url, re.IGNORECASE)\n",
    "        return search.groups()[2]\n",
    "    except Exception as e:\n",
    "        print(f'Exception for {url} - {e}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extended_url(url):\n",
    "    extended_url = ''\n",
    "    domain = ''\n",
    "    try:\n",
    "        extended_url = requests.head(url).headers['location']\n",
    "    except (KeyError, TypeError) as e:\n",
    "        print(f'Key/Type Exception for {url} - {e}')\n",
    "    except requests.exceptions.MissingSchema as e:\n",
    "        print(f'Missing schema for {url}')\n",
    "        corrected_url =  'http://'+url\n",
    "        extended_url = requests.head(corrected_url).headers['location']\n",
    "    except Exception as e:\n",
    "        print(f'Exception for {url} - {e}')\n",
    "    domain = extract_domain(extended_url)    \n",
    "    if domain and domain in ['trib.al', 'bit.ly', 'tinyurl.com']:\n",
    "        extended_url = requests.head(extended_url).headers['location']\n",
    "        domain = extract_domain(extended_url)\n",
    "    return extended_url, domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_url(url):\n",
    "    pos = url.find('https')\n",
    "    if url[-1] == '.':\n",
    "        url = url[0:-1]\n",
    "    if pos > 0:\n",
    "        return url[pos:]\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short_expanded_url_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_extended_url('bit.ly/2UeUZGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for url in short_url_list:\n",
    "#     if url not in short_expanded_url_map.keys():\n",
    "#         expanded_url, domain = get_extended_url(cleanup_url(url))\n",
    "#         if expanded_url != '':\n",
    "#             short_expanded_url_map[url] = [expanded_url, domain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store short_expanded_url_map\n",
    "%store -r short_expanded_url_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[short_url, val[1]]\n",
    "        for short_url, val in short_expanded_url_map.items()]\n",
    "corrected_domain_df = pd.DataFrame(data, columns=['expandedLinks', 'corrected_domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_domain_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_extended_url('https://bit.ly/3nPNfYa?cc=539458b52df6684692eb0107760bd294')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_domain_df[corrected_domain_df.corrected_domain.isin(['trib.al', 'bit.ly', 'tinyurl.com'])][['expandedLinks', 'corrected_domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_updated_domain_df = pd.merge(news_df,corrected_domain_df,how='left',left_on=['expandedLinks'],right_on=['expandedLinks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_updated_domain_df[news_updated_domain_df.corrected_domain.notnull()][['domain', 'corrected_domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp['domain'] = temp[['domain', 'corrected_domain']].apply(lambda x: x[1] if pd.notnull(x[1]) else x[0])\n",
    "news_updated_domain_df['domain'] = np.where(news_updated_domain_df['corrected_domain'].notnull(), news_updated_domain_df['corrected_domain'], news_updated_domain_df['domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_updated_domain_df[news_updated_domain_df.corrected_domain.notnull()][['domain', 'corrected_domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_updated_domain_df = news_updated_domain_df.drop(columns=['corrected_domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links404 = news_updated_domain_df[news_updated_domain_df.domain.isin(['trib.al', 'bit.ly', 'tinyurl.com'])][['id', 'expandedLinks', 'domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(links404)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining news_updated_domain_df with ratings_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_ratings_df = pd.merge(news_updated_domain_df,ratings_df,how='left',left_on=['domain'],right_on=['domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_ratings_df['rating'] = news_ratings_df['rating'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonna_ratings = news_ratings_df[news_ratings_df.rating.notnull()].domain.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nonna_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ratings = news_ratings_df[news_ratings_df.rating.isnull()].domain.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nan_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_ratings_df[(news_ratings_df['rating'].isnull())][['domain']].drop_duplicates().sort_values('domain', ascending=True).to_csv('no_ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(news_ratings_df[news_ratings_df.rating.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(news_ratings_df[news_ratings_df.rating.notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_ratings_df[news_ratings_df['rating'] == -1][['id', 'domain']].groupby('domain').count().sort_values('id', ascending=False).to_csv('domain_rating_null.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_ratings_df['credible'] = news_ratings_df.rating.apply(lambda x: True if x >= 60 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_ratings_df.to_csv('news_ratings_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}